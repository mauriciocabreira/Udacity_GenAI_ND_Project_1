This is the project for Module 1 of the udacity Generative AI Nanodegree (https://www.udacity.com/course/generative-ai--nd608)

This project brings together all of the essential components of a PyTorch + Hugging Face training and inference process. Specifically: Load a pre-trained model and evaluate its performance Perform parameter-efficient fine tuning using the pre-trained model Perform inference using the fine-tuned model and compare its performance to the original model

Choices for this project:

PEFT technique: LoRA
Model: GPT-2
Evaluation approach: Transformer Trainer
Fine-tuning dataset: Rotten Tomatoes (https://huggingface.co/datasets/rotten_tomatoes)

