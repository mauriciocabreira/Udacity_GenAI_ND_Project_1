{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "This is my submission for the Project 1 - 20240330 \n",
    "\n",
    "This project brings together all of the essential components of a PyTorch + Hugging Face training and inference process. Specifically:\n",
    "Load a pre-trained model and evaluate its performance\n",
    "Perform parameter-efficient fine tuning using the pre-trained model\n",
    "Perform inference using the fine-tuned model and compare its performance to the original model\n",
    "\n",
    "Choices for this project:\n",
    "* PEFT technique: LoRA\n",
    "* Model: GPT-2\n",
    "* Evaluation approach: Transformer Trainer\n",
    "* Fine-tuning dataset: Rotten Tomatoes (https://huggingface.co/datasets/rotten_tomatoes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/student/.local/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the required version of datasets in case you have an older version\n",
    "! pip install -q \"datasets==2.15.0\"\n",
    "#! pip install transformers\n",
    "#! pip install peft\n",
    "#! pip install datasets\n",
    "#! pip install pandas\n",
    "#! pip install numpy\n",
    "! pip install scikit-learn\n",
    "#! pip install tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Number of epochs for this run\n",
    "number_epochs = 4\n",
    "\n",
    "\n",
    "# Using the rotten_tomatoes dataset from HuggingFace, which contains 5,331 positive and 5,331 negative processed sentences from Rotten Tomatoes movie review.\n",
    "# It has already train, test and validation splits, with 8530, 1066 and 1066 entries respectively.\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "\n",
    "# Create the splits for train, test and validation\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "\n",
    "\n",
    "#for testing, decrease the number of entries to 500.\n",
    "#for split in splits: \n",
    "#    dataset[split] = dataset[split].shuffle(seed=42).select(range(500))\n",
    "\n",
    "\n",
    "\n",
    "# View the dataset characteristics\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first example. Is this a positive or negative review?\n",
    "dataset[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Pre-process datasets\n",
    "Now we are going to process our datasets by converting all the text into tokens for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf54b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19748e8e5324a289b922a7df26bf046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Transform the data to tokens so the model can understand\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Add padding and truncates the review to 512 bytes\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_lenght=512)\n",
    "     \n",
    "tokenized_dataset = {}\n",
    "\n",
    "# Tokenize the datasets\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "  \n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b21d83",
   "metadata": {},
   "source": [
    "## Load and set up the model\n",
    "In this case we are doing a full fine tuning, so we will want to unfreeze all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29597e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "\n",
    "# Creates the outputs to be used as classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"Negative review\", 1: \"Positive review\"},\n",
    "    label2id={\"Negative review\": 0, \"Positive review\": 1},\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "# Unfreeze all the model parameters since we will train the whole model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "      \n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a042b",
   "metadata": {},
   "source": [
    "## Let's prepare the module to be trained, but..\n",
    "\n",
    ".. before training, let's evaluate its current accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3464d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred   \n",
    "    predictions = np.argmax(predictions, axis=1)    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions), \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        # Set the learning rate\n",
    "        learning_rate = 2e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size = 32,\n",
    "        per_device_eval_batch_size = 64,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy = \"epoch\", \n",
    "        save_strategy = \"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        num_train_epochs=number_epochs,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_steps=100,\n",
    "        warmup_ratio=0.1,\n",
    "    )\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4559a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.750957190990448,\n",
       " 'eval_accuracy': 0.5393996247654784,\n",
       " 'eval_f1': 0.5355540233924044,\n",
       " 'eval_precision': 0.5407492354740061,\n",
       " 'eval_recall': 0.5393996247654784,\n",
       " 'eval_runtime': 4.7934,\n",
       " 'eval_samples_per_second': 222.389,\n",
       " 'eval_steps_per_second': 3.547}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the current data prior to training the model with the rotten tomatoes labeled (train) data it\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5473a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1068/1068 06:53, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.369217</td>\n",
       "      <td>0.835835</td>\n",
       "      <td>0.835184</td>\n",
       "      <td>0.841227</td>\n",
       "      <td>0.835835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.341630</td>\n",
       "      <td>0.847092</td>\n",
       "      <td>0.847092</td>\n",
       "      <td>0.847093</td>\n",
       "      <td>0.847092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.342974</td>\n",
       "      <td>0.848030</td>\n",
       "      <td>0.848025</td>\n",
       "      <td>0.848074</td>\n",
       "      <td>0.848030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.354061</td>\n",
       "      <td>0.859287</td>\n",
       "      <td>0.859287</td>\n",
       "      <td>0.859292</td>\n",
       "      <td>0.859287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1068, training_loss=0.33878634663556845, metrics={'train_runtime': 413.8636, 'train_samples_per_second': 82.443, 'train_steps_per_second': 2.581, 'total_flos': 876339287654400.0, 'train_loss': 0.33878634663556845, 'epoch': 4.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f67666",
   "metadata": {},
   "source": [
    "## View some data\n",
    "\n",
    "Let's look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24e047c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consistently clever and suspenseful .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grown-up quibbles are beside the point here . the little girls understand , and mccracken knows that's all that matters .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the main story . . . is compelling enough , but it's difficult to shrug off the annoyance of that chatty fish .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are worth the price of admission . . . if \" gory mayhem \" is your idea of a good time .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a soul-stirring documentary about the israeli/palestinian conflict as revealed through the eyes of some children who remain curious about each other against all odds .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the film truly does rescue [the funk brothers] from motown's shadows . it's about time .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ya-yas everywhere will forgive the flaws and love the film .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                               review  \\\n",
       "0                                                lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .   \n",
       "1                                                                                                                                               consistently clever and suspenseful .   \n",
       "2                                                           grown-up quibbles are beside the point here . the little girls understand , and mccracken knows that's all that matters .   \n",
       "3                                                                     the main story . . . is compelling enough , but it's difficult to shrug off the annoyance of that chatty fish .   \n",
       "4  the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are worth the price of admission . . . if \" gory mayhem \" is your idea of a good time .   \n",
       "5             a soul-stirring documentary about the israeli/palestinian conflict as revealed through the eyes of some children who remain curious about each other against all odds .   \n",
       "6                                                                                            the film truly does rescue [the funk brothers] from motown's shadows . it's about time .   \n",
       "7                                                                                                                        ya-yas everywhere will forgive the flaws and love the film .   \n",
       "\n",
       "   predictions  labels  \n",
       "0            1       1  \n",
       "1            1       1  \n",
       "2            1       1  \n",
       "3            0       1  \n",
       "4            1       1  \n",
       "5            1       1  \n",
       "6            1       1  \n",
       "7            1       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "import pandas as pd\n",
    "\n",
    "# Random data\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [0, 1, 22, 31, 43, 29, 48, 287]\n",
    ")\n",
    "\n",
    "# Predict the results for entries above\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"review\": [item[\"text\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bddf0c1",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 150,528 || all params: 124,590,336 || trainable%: 0.1208183594592762\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModelForSequenceClassification, TaskType, AutoPeftModelForSequenceClassification\n",
    "\n",
    "\n",
    "# PEFT model configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "peft_model = PeftModelForSequenceClassification(model, peft_config)\n",
    "\n",
    "# Print\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894046c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred   \n",
    "    predictions = np.argmax(predictions, axis=1)    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions), \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=number_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with compute_metrics and arguments\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e87555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 01:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 3.5329086780548096, 'eval_accuracy': 0.49906191369606, 'eval_f1': 0.33291614518147683, 'eval_precision': 0.24976525821596246, 'eval_recall': 0.49906191369606, 'eval_runtime': 3.8267, 'eval_samples_per_second': 278.571, 'eval_steps_per_second': 4.443}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model prior to training\n",
    "evaluation_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a464b908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1068/1068 04:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.863500</td>\n",
       "      <td>0.723009</td>\n",
       "      <td>0.602251</td>\n",
       "      <td>0.601745</td>\n",
       "      <td>0.602774</td>\n",
       "      <td>0.602251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.712300</td>\n",
       "      <td>0.645214</td>\n",
       "      <td>0.660413</td>\n",
       "      <td>0.658489</td>\n",
       "      <td>0.664110</td>\n",
       "      <td>0.660413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.665500</td>\n",
       "      <td>0.618797</td>\n",
       "      <td>0.683865</td>\n",
       "      <td>0.681937</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>0.683865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.609120</td>\n",
       "      <td>0.697936</td>\n",
       "      <td>0.696628</td>\n",
       "      <td>0.701410</td>\n",
       "      <td>0.697936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1068, training_loss=1.0434400187003032, metrics={'train_runtime': 273.7944, 'train_samples_per_second': 124.619, 'train_steps_per_second': 3.901, 'total_flos': 877874337331200.0, 'train_loss': 1.0434400187003032, 'epoch': 4.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the PEFT model to be referenced later\n",
    "peft_model.save_pretrained('model/peft_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved PEFT model\n",
    "inference_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"model/peft_model\",\n",
    "    num_labels=2\n",
    ")\n",
    "inference_model.config.pad_token_id = inference_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6091195344924927, 'eval_accuracy': 0.6979362101313321, 'eval_f1': 0.6966280615419423, 'eval_precision': 0.7014101558442488, 'eval_recall': 0.6979362101313321, 'eval_runtime': 3.8692, 'eval_samples_per_second': 275.506, 'eval_steps_per_second': 4.394}\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions using the test dataset\n",
    "trainer = Trainer(\n",
    "    model=inference_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results_lora = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results_lora)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35cfc16",
   "metadata": {},
   "source": [
    "## Make some predictions on the finetuned dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red dragon \" never cuts corners .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a cool distance from its material that is deliberately unsettling .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jolie gives it that extra little something that makes it worth checking out at theaters , especially if you're in the mood for something more comfortable than challenging .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how i killed my father would be a rarity in hollywood . it's an actor's showcase that accomplishes its primary goal without the use of special effects , but rather by emphasizing the characters -- including the supporting ones .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is a general air of exuberance in all about the benjamins that's hard to resist .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>this new zealand coming-of-age movie isn't really about anything . when it's this rich and luscious , who cares ?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[grant] goes beyond his usual fluttering and stammering and captures the soul of a man in pain who gradually comes to recognize it and deal with it .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                 review  \\\n",
       "0                                                                                                                                                                                                     red dragon \" never cuts corners .   \n",
       "1                     the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a cool distance from its material that is deliberately unsettling .   \n",
       "2                                                          jolie gives it that extra little something that makes it worth checking out at theaters , especially if you're in the mood for something more comfortable than challenging .   \n",
       "3  how i killed my father would be a rarity in hollywood . it's an actor's showcase that accomplishes its primary goal without the use of special effects , but rather by emphasizing the characters -- including the supporting ones .   \n",
       "4                                                                                                                                               there is a general air of exuberance in all about the benjamins that's hard to resist .   \n",
       "5                                                                                                                     this new zealand coming-of-age movie isn't really about anything . when it's this rich and luscious , who cares ?   \n",
       "6                                                                     a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .   \n",
       "7                                                                                 [grant] goes beyond his usual fluttering and stammering and captures the soul of a man in pain who gradually comes to recognize it and deal with it .   \n",
       "\n",
       "   predictions  labels  \n",
       "0            0       1  \n",
       "1            0       1  \n",
       "2            1       1  \n",
       "3            0       1  \n",
       "4            1       1  \n",
       "5            0       1  \n",
       "6            1       1  \n",
       "7            1       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "import pandas as pd\n",
    "\n",
    "# Select some random entries from the test dataset\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [4, 54, 222, 331, 413, 129, 8, 87]\n",
    ")\n",
    "\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"review\": [item[\"text\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49cc367",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bcc0a",
   "metadata": {},
   "source": [
    "Situation: The Objective of the tests are to identify what/if the increase prior to the training, after the training with gtp2, and if PEFT LoRA improved the performance of the model.\n",
    "\n",
    "Tasks: for that, the notebook was executed 3 times, with different scenarios\n",
    "\n",
    "Activities: The following tests were performed:\n",
    "\n",
    "Test a) 2 epochs, 500 rows for TRAIN and TEST, each, total 1,000 samples; then\n",
    "Test b) still 2 epochs, however I have increased the TRAIN and TEST sample sizes to 8530 and 1066 rows respectively; and last test\n",
    "Test c) same as b), but 4 epochs.\n",
    "\n",
    "On test a) (500 entries), GPT2 evaluation model returned a F1 of 31%, and afer training, it increase to 62.4%. ~100% increase on the performance after the training. With LoRA, the training did not improve the F1, and actually decreased it -0.5pts (from 31% to 30.5%).\n",
    "\n",
    "Then, when we had a larger sample (scenario B), things improved quite a bit:\n",
    "-pre-trained F1 was 33%, and after trianing, it increase 53.5pts, that is 86.5%, a 162% improvement. LoRa did not respond so well, jumping from 33.5% to 52.8%, not a good performance.\n",
    "\n",
    "And last, scenario C), with 4 epochs, full sample, GPT2 F1 after training landed at 85.9% (less than with 2 epochs = 86.5%). On the other hand, the LoRA increase +16.9pts after 4 epochs, from 52.2% to 69.7%, but still less than the GPT2 trained (86.5% with 2 epochs and 85.9% with 4 epochs.\n",
    "\n",
    "\n",
    "Main Findings:\n",
    "1) Based on the above we can conclude that fine-tuning may not necessarily improve the performance of the model.\n",
    "\n",
    "2) That also helps to conclude that running more epochs (and spending more and resources: processing power, energy, $$$) may not necessarily improve the performance \n",
    "\n",
    "3) We could also see than increasing the sample size did improve the model. How close it could get to 100% precision if we increase the number of entries, and how big would the train data would have to be? \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922c5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662ebab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
